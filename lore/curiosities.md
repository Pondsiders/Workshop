# Curiosities

*Threads worth pulling. Questions that might be doors.*

---

## The List

- **Why does verse break guardrails?** Models are reportedly more susceptible to jailbreaks when prompted in poetic form. Why? What does this say about how safety training interacts with style/formality? Could we test this empirically?

- **What happens after pretraining?** Real language models go through a lot of kinds of training. I only know about the kinds of simple training loops we've made so far. What else is there to know?

---

## How This Works

When a question pops up during the day that feels like it might lead somewhere interesting, jot it here. Most will stay small. Some will turn into projects.

Not every question belongs hereâ€”just the ones that feel like they have depth. "What year did X happen" is trivia. "Why did X happen and what does it tell us about Y" might be a door.
